<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[knn]]></title>
    <url>%2F2019%2F02%2F18%2Fknn%2F</url>
    <content type="text"><![CDATA[KNN是通过测量不同特征值之间的距离进行分类。它的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别，其中K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 KNN算法的一般流程搜集数据：可以使用任何方法准备数据：距离计算所需要的数值，最好是结构化的数据格式建立一个KNN.py，里面放置数据和标签。 12345678910# _*_ encoding=utf8 _*_from numpy import *import operatordef createDataSet(): group = array([1.1,1.0],[1.0,1.0],[0,0],[0,0.1]) labels = ['A','A','B','B'] return group,labels 分析数据：可以使用任何方法四个点很明显可以看见，分为两类，A标签有两个点，B标签有两个点。 训练算法：此步骤不适用于KNN算法KNN的伪代码思想：对未知类别属性的数据集中的每个点依次执行以下操作：（1）、计算已知类别数据集中的点与当前点之间的操作；（2）、按照距离递增次序排序（3）、选取与当前点距离最小的k个点（4）、确定前k个点所在类别出现的概率（5）、返回前k个点出现概率最高的类别作为当前点的预测分类 KNN的python代码 1234567891011121314151617181920212223def classify(inX,dataSet,labels,k): dataSetSize = dataSet.shape[0] print(dataSetSize) # 获取第一维的维度 4*2 也就是4 # tile 重复inX维度(4,1) inX = [0,0] ==&gt;先横向复制4次，纵向复制1次，也就是本身 最后的维度(4,2) # 这儿求欧式距离，都是求到0 0 的距离 以下几行都是求欧式距离 diffMat = tile(inX, (dataSetSize, 1)) - dataSet sqDiffMat = diffMat ** 2 # 按列求和，也可按行求和axis=1 sqDistances = sqDiffMat.sum(axis=1) print(sqDistances) distances = sqDistances ** 0.5 print(distances) # 返回从小到大的数值的索引 sortedDistIndicies = distances.argsort() print(sortedDistIndicies) classCount = &#123;&#125; for i in range(k): voteIlabel = labels[sortedDistIndicies[i]] # 统计离0 0 最近的范围的标签是什么， classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1 sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True) print(sortedClassCount[0][0]) # 输出预测属于哪一类 测试算法：计算错误率检测分类的结果 123if __name__ == '__main__': group,labels = createDataSet() classify([0,0],group,labels,3) 使用算法：首先需求输入样本数据和结构化的输出结果，然后运行KNN算法判定输入数据分别属于哪一个分类，最后应用对计算出的分类执行后续的处理。约会问题在线约会想找一个适合自己的对象，她把每一个约会对象划分为三类人。 不喜欢的人 魅力一般的人 极具魅力的人 根据哪些特征可以把一个人划分到其中一类呢，她是根据三个特点的分值占比，将一个人划分到某一类，这三个特点是： 每年获得飞行常客里程数 玩视频游戏所占时间百分比 每周消费的冰淇淋公升数数据特征如下： 1234567840920 8.326976 0.953952 314488 7.153469 1.673904 226052 1.441871 0.805124 175136 13.147394 0.428964 138344 1.669788 0.134296 172993 10.141740 1.032955 135948 6.830792 1.213192 342666 13.276369 0.543880 3 首先让文件数据读入内存，训练数据和标记数据分开存储 1234567891011121314def file2matrix(filename): fr = open(filename) numberOfLines = len(fr.readlines()) returnMat = zeros((numberOfLines,3)) classLabelVector = [] fr = codecs.open(filename,'r','utf-8') index = 0 for line in fr.readlines(): line = line.strip() listFromLine = line.split('\t') returnMat[index,:] = listFromLine[0:3] classLabelVector.append(int(listFromLine[-1])) index += 1 return returnMat,classLabelVector 查看一下内存中的训练数据和标签数据代码： 123456if __name__ == '__main__': # group,labels = createDataSet() # classify([0,0],group,labels,3) datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') print(datingDataMat[:3]) print(datingLabels[0:20]) 结果： 1234[[4.092000e+04 8.326976e+00 9.539520e-01] [1.448800e+04 7.153469e+00 1.673904e+00] [2.605200e+04 1.441871e+00 8.051240e-01]][3, 2, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3] 有了数据，有了代码，有了结果标签，就可以从训练数据抽取出一条数据，看看结果预测的对不对选取最后一条数据，数据如下，把他从训练数据文件中删除： 143757 7.882601 1.332446 3 找前3个点出现的概率，测试代码如下： 1234567if __name__ == '__main__': # group,labels = createDataSet() # classify([0,0],group,labels,3) datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') print(datingDataMat[:3]) print(datingLabels[0:20]) classify([43757,7.882601,1.332446], datingDataMat, datingLabels, 3) 。。。预测出来是1，看来是拿到的特征不够，改一行代码试试，找与前100个点的距离 1classify([43757,7.882601,1.332446], datingDataMat, datingLabels, 3) nice，预测出来是3了。 使用Matplotlib创建散点图还是使用刚刚从文件读取出来的数据，查看玩视频游戏消耗时间占比和每周消费冰淇淋的公升数这两个数值，（第一个值太大，不压缩的话其他特征就看不见了，所以不选第一列的值）代码： 123456if __name__ == '__main__': datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') fig = plt.figure() ax = fig.add_subplot(111) ax.scatter(datingDataMat[:,1],datingDataMat[:,2]) plt.show() 结果图横轴是玩视频游戏消耗时间占比，纵轴是每周消费冰淇淋的公升数由于颜色一样，这样的数据显示没什么太大的意义，现在加上标签分类，区分颜色查看这个点属于那一类。下图就是查看第二列和第三列数据，显示的属于哪一类（不喜欢、一般魅力、极具魅力）修改的代码： 12ax.scatter(datingDataMat[:,1],datingDataMat[:,2], 15.0*array(datingLabels),15.0*array(datingLabels)) 结果图： 归一化数值刚刚所说，第一列的数据范围远远大于第二列和第三列的数值范围，所以第一列带来的影响也远远大于其他两列，归一化就是将数据利用一定的比例压缩在0-1之间，这儿使用的方法如下newValue = (oldValue-min)/(max-min)也就是，（当前数据-该列最小数据）/（该列的最大数据-该列的最小数据）代码： 123456789def autoNorm(dataSet): minVals = dataSet.min(0) maxVals = dataSet.max(0) ranges = maxVals - minVals normDataSet = zeros(shape(dataSet)) m = dataSet.shape[0] normDataSet = dataSet - tile(minVals, (m,1)) normDataSet = normDataSet/tile(ranges, (m,1)) return normDataSet, ranges, minVals 好像给了测试数据，测试方法如下： 12345678910111213def datingClassTest(): hoRatio = 0.50 #hold out 10% datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') normMat, ranges, minVals = autoNorm(datingDataMat) m = normMat.shape[0] numTestVecs = int(m*hoRatio) errorCount = 0.0 for i in range(numTestVecs): classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3) print("the classifier came back with: %d, the real answer is: %d" % (classifierResult, datingLabels[i])) if (classifierResult != datingLabels[i]): errorCount += 1.0 print("the total error rate is: %f" % (errorCount/float(numTestVecs))) print(errorCount) 运行测试代码： 12if __name__ == '__main__': datingClassTest() 查看结果： 1234567...the classifier came back with: 2, the real answer is: 2500the classifier came back with: 1, the real answer is: 1500the classifier came back with: 1, the real answer is: 1the total error rate is: 0.064128 可以看见约会问题的分类错误率是6.4128%全部代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394# _*_ encoding=utf8 _*_from numpy import *import operatorimport codecsimport matplotlibimport matplotlib.pyplot as pltdef createDataSet(): group = array([[1.1,1.0],[1.0,1.0],[0.0,0.0],[0.0,0.1]]) labels = ['A','A','B','B'] return group,labelsdef classify(inX,dataSet,labels,k): dataSetSize = dataSet.shape[0] print(dataSetSize) # 获取第一维的维度 4*2 也就是4 # tile 重复inX维度(4,1) inX = [0,0] ==&gt;先横向复制4次，纵向复制1次，也就是本身 最后的维度(4,2) # 这儿求欧式距离，都是求到0 0 的距离 以下几行都是求欧式距离 diffMat = tile(inX, (dataSetSize, 1)) - dataSet sqDiffMat = diffMat ** 2 # 按列求和，也可按行求和axis=1 sqDistances = sqDiffMat.sum(axis=1) # print(sqDistances) distances = sqDistances ** 0.5 # print(distances) # 返回从小到大的数值的索引 sortedDistIndicies = distances.argsort() # print(sortedDistIndicies) classCount = &#123;&#125; for i in range(k): voteIlabel = labels[sortedDistIndicies[i]] # 统计离0 0 最近的范围的标签是什么， classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1 sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True) # print(sortedClassCount[0][0]) # 输出预测属于哪一类 return sortedClassCount[0][0]def file2matrix(filename): fr = open(filename) numberOfLines = len(fr.readlines()) returnMat = zeros((numberOfLines,3)) classLabelVector = [] fr = codecs.open(filename,'r','utf-8') index = 0 for line in fr.readlines(): line = line.strip() listFromLine = line.split('\t') returnMat[index,:] = listFromLine[0:3] classLabelVector.append(int(listFromLine[-1])) index += 1 return returnMat,classLabelVectordef autoNorm(dataSet): minVals = dataSet.min(0) maxVals = dataSet.max(0) ranges = maxVals - minVals normDataSet = zeros(shape(dataSet)) m = dataSet.shape[0] normDataSet = dataSet - tile(minVals, (m,1)) normDataSet = normDataSet/tile(ranges, (m,1)) return normDataSet, ranges, minValsdef datingClassTest(): hoRatio = 0.50 #hold out 10% datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') #load data setfrom file normMat, ranges, minVals = autoNorm(datingDataMat) m = normMat.shape[0] numTestVecs = int(m*hoRatio) errorCount = 0.0 for i in range(numTestVecs): classifierResult = classify(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3) print("the classifier came back with: %d, the real answer is: %d" % (classifierResult, datingLabels[i])) if (classifierResult != datingLabels[i]): errorCount += 1.0 print("the total error rate is: %f" % (errorCount/float(numTestVecs))) print(errorCount)if __name__ == '__main__': # group,labels = createDataSet() # classify([0,0],group,labels,3) # datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') # print(datingDataMat[:3]) # print(datingLabels[0:20]) # classify([43757,7.882601,1.332446], datingDataMat, datingLabels, 100) # fig = plt.figure() # ax = fig.add_subplot(111) # ax.scatter(datingDataMat[:,1],datingDataMat[:,2], # 15.0*array(datingLabels),15.0*array(datingLabels)) # plt.show() datingClassTest() 手写体识别数据分类类似之前的约会问题，构造输入和标签（10分类）就好。构造输入方法也就是读取文件的方法：查看手写体的文件，如下这样一个矩阵刻画出来的阿拉伯数字。 12345678910111213141516171819202122232425262728293031320000000000000111100000000000000000000000000011111110000000000000000000000011111111110000000000000000000111111111111110000000000000000001111111011111100000000000000000111111100000111100000000000000001111111000000011100000000000000011111110000000111100000000000000111111100000000111000000000000001111111000000001110000000000000011111100000000011110000000000000111111000000000011100000000000001111110000000000111000000000000001111110000000000111000000000000011111100000000001110000000000000111111000000000011100000000000001111110000000000111000000000000111111100000000011110000000000001111011000000000111100000000000011110000000000011110000000000000011110000000000011110000000000000111100000000001111100000000000001111000000000111110000000000000011110000000011111000000000000000011100000011111100000000000000000111100011111110000000000000000001111111111111100000000000000000001111111111111000000000000000000011111111111100000000000000000000011111111100000000000000000000000011111000000000000000000000000000011000000000000000000 123456789# 手写体识别是32*32的def img2vector(filename): returnVect = zeros((1,1024)) fr = open(filename) for i in range(32): lineStr = fr.readline() for j in range(32): returnVect[0,32*i+j] = int(lineStr[j]) return returnVect 测试代码: 12345678910111213141516171819202122232425def handwritingClassTest(): hwLabels = [] trainingFileList = os.listdir('../data/trainingDigits') m = len(trainingFileList) trainingMat = zeros((m,1024)) for i in range(m): fileNameStr = trainingFileList[i] fileStr = fileNameStr.split('.')[0] classNumStr = int(fileStr.split('_')[0]) hwLabels.append(classNumStr) trainingMat[i,:] = img2vector('../data/trainingDigits/%s' % fileNameStr) testFileList = os.listdir('../data/testDigits') errorCount = 0.0 mTest = len(testFileList) for i in range(mTest): fileNameStr = testFileList[i] fileStr = fileNameStr.split('.')[0] classNumStr = int(fileStr.split('_')[0]) vectorUnderTest = img2vector('../data/testDigits/%s' % fileNameStr) classifierResult = classify(vectorUnderTest, trainingMat, hwLabels, 3) print("the classifier came back with: %d, the real answer is: %d" % (classifierResult, classNumStr)) if (classifierResult != classNumStr): errorCount += 1.0 print("\nthe total number of errors is: %d" % errorCount) print("\nthe total error rate is: %f" % (errorCount/float(mTest))) 结果： 123the total number of errors is: 11the total error rate is: 0.011628 Tensorflow版本KNN代码1234567891011121314151617181920212223242526272829303132333435363738394041424344# _*_ encoding=utf8 _*_import numpy as npimport tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# 导入手写体识别的数据mnist = input_data.read_data_sets("../data", one_hot=True)# 训练集和测试集X_train, Y_train = mnist.train.next_batch(5000) # 数据和labelsX_test, Y_test = mnist.test.next_batch(100)# 定义输入x_train = tf.placeholder(tf.float32, shape=(None,784))x_test = tf.placeholder(tf.float32, shape=(784))# L1距离也就是城市街区距离 |x1-x2|+|y1-y2|distance = tf.reduce_sum(tf.abs(tf.add(x_train,tf.negative(x_test))),reduction_indices = 1)# 返回最近的坐标，0纵轴 1横轴pred = tf.arg_min(distance, 0)accuracy = 0# 初始化init = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) for i in range(len(X_test)): # 获取当前样本的最近邻索引，当前样本和每一个训练的样本找一个最近的l1距离，得到这个最小距离的下标 nn_index = sess.run(pred, feed_dict=&#123;x_train:X_train, x_test: X_test[i, :]&#125;) # 由最邻近索引找到label,然后最邻近的label与真实标签比较 np.argmax找最大的下标 # 由l1距离找到的最小值对应的坐标，通过该最坐标找到对应行label的最大值的下标，这个下标对应的就是数字的大小 print("预测次数", i, "预测标签:", np.argmax(Y_train[nn_index]),"真实标签:", np.argmax(Y_test[i])) # 计算准确率 if np.argmax(Y_train[nn_index]) == np.argmax(Y_test[i]): accuracy += 1print("Accuracy:", float(accuracy)/len(X_test))]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>knn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[书单]]></title>
    <url>%2F2019%2F02%2F18%2F%E4%B9%A6%E5%8D%95%2F</url>
    <content type="text"><![CDATA[《架构整洁之道》]]></content>
      <categories>
        <category>书单</category>
      </categories>
      <tags>
        <tag>书单</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018目标]]></title>
    <url>%2F2018%2F11%2F22%2F2018%E7%9B%AE%E6%A0%87%2F</url>
    <content type="text"><![CDATA[思前想后，在2018结尾之际，好吧就是结尾，但是也需要在春节之前给自己一个目标，安慰一下这一年犹豫不决的心吧。 我觉得应该从书单和知识点都出发吧。整理一下思路，好像目前博客不能评论... ## 书单 &lt;!--more--&gt; ## 知识点 word2vec 的CBOW和Skip-Gram fasttext textcnn sent2vec capsnet attention seq2seq idcnn Encoder-Decoder]]></content>
      <categories>
        <category>计划</category>
      </categories>
      <tags>
        <tag>计划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一篇文章]]></title>
    <url>%2F2018%2F11%2F04%2F%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[有种爱，只离你一转身的距离 他是你前世遗落的一滴泪，今生，不管谁人装饰你的梦，他的梦只有你是唯一的点缀;不管你呼唤的人是谁，你的名字是他心里梦里唯一的执念不悔。 ——题记 人世间，或许你本是烙在他心头的一颗朱砂，最后却成了一朵让他可望而不可及的彼岸花。不知是光阴的交错，还是轮回的因果，有种爱，永远只离你一转身的距离，一旦开始，永无结束。你来，瘦了他的幽梦;你去，肥了他的相思。 爱是种很玄的东西，说不清，道不明，剪不断，理还乱。世上，有种爱明知没有结果，却依然坚守原地，不舍离去，哪怕握不住你的一丝余温，他依然选取默默为你守候。一路来去，他的心门只为你独开，他的山城只为你独驻，他的白天只为你旖旎，他的黑夜只为你流连。哪怕他因为爱你，心入住荒岛，他还是会以最深情的眼神，看着你幸福。 自爱上你的那天起，思念便成了他戒不掉的瘾。你的一言一笑，一颦一蹙，无不牵动他的心，百千尘思，他唯念一缕;万千红颜，他唯恋一人。他愿意一生漂泊浪迹在你的故事里，甘愿为你鞍前马后，马首是瞻，即使你从未给他一句承诺，即使你从未给他半分感情，他依然无悔无怨。 正如张爱玲说的“等待雨，是伞一世的宿命”。当你深植在他心里，那么任何力量都无法将你从他心中除去。不管你是不是他身边的卷帘人，不管你是不是他罗帐里的共眠者，他的目光将一向被你牵引，他的感情故事里，你必须是无可替代的主角，从此，他的等待里，愿望里，祝福里，牵挂里，都会有你。他能够戒掉一切，但就是戒不掉你。 只因当初在人群中多看了你一眼，从此，他再未走远。他不轻易靠近打扰，是怕自己扰了你的生活步调;他不轻易对你开口言爱，是怕那样做是一种冒犯，是一种亵渎，是一种伤害;他不轻易换手机号码，是怕你担心找他不见。因为爱，他能够为你低到尘埃，能够为你放弃日月山河，能够为你浪迹海角天涯。他不在乎他的四季有没有春天，因为只有你才是他的人间四月天;他不在乎他生活在白天还是黑夜，因为只有你才能照亮他的全世界。 其实他害怕寂寞，但他因为你会让自己陷进很深的寂寞;其实他害怕孤独，但他因为你会让自己紧紧追随着孤独。他多么期望，你能懂他沉默，懂他无声，懂他的欲言又止。有时你看不见他，是因为他悄悄藏在了你身后;有时你听不见他，是因为他偷偷用静默伪装了自己。纵然他离你山高水远，只要你对他呼唤，他必须能快速抵达;纵然他有万事牵绊，只要你对他招手，他必须会义无反顾。 你让他难过了，他会笑着说无所谓;你让他受伤了，他会找理由来原谅。你若欢笑，也许他会比你笑得更灿烂;你若流泪，也许他会比你更难过。因为你，他会爱上你住的那座城，你住的地方，是他梦里梦外辗转的心驰神往。距离，隔不断他的爱恋;时间，冲不淡他的思念。任季节轮回，他始终认为，今生只为你而来，哪怕今生终是错过，他还会傻傻地预约来生。 走在南国，他会渴望共你摇橹，游遍江南的烟雨水乡;走在北国，他会期盼与你共沐飞雪，穿越雪帘走向梦中的童话。他的脚步随你飘移，他的心跳随你跳动。莫名的，看到一个与你相似的身影，听见一个与你相似的声音，他都会激动良久。无论何时，无论何地，他都在用另一种不为你所知的方式，悄悄地爱你。 徐志摩说：“一生至少该有一次，为了某个人而忘了自己，不求有结果，不求同行，不求以前拥有，甚至不求你爱我，只求在我最美的年华里，遇到你。”他就是如此，今生遇见你，他觉得是他的幸福，尽管这幸福里交杂着万千痛苦。 人生有期，但这份守候永不落幕，繁华红尘，谁染指了谁的幸福于他而言，江山如画，怎敌你眉间的一点朱砂你，永远是他描不完的画、读不厌的景。无论何时，你若回首，你会发现，他永远只离你一转身的距离，人在那里，从未稍离!]]></content>
      <categories>
        <category>hexo使用教程</category>
      </categories>
      <tags>
        <tag>散文</tag>
        <tag>测试</tag>
      </tags>
  </entry>
</search>
