<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[spring多数据源]]></title>
    <url>%2F2019%2F04%2F14%2Fspring%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[spring单数据源使用jdbc]]></title>
    <url>%2F2019%2F04%2F14%2Fspring%E5%8D%95%E6%95%B0%E6%8D%AE%E6%BA%90%E4%BD%BF%E7%94%A8jdbc%2F</url>
    <content type="text"><![CDATA[在实际的生产应用中，会涉及到操作数据库，在这使用内嵌的h2数据库，简单方便操作。 导入依赖首先需要导入项目需要的依赖，目前需要的依赖有：actuator,H2,JDBC,Lombok,web1、actuator:actuator是监控系统健康情况的工具。2、H2 数据库3、jdbc:对数据库的数据需要使用到jdbc操作4、Lombok:简单理解就是Lombok想要解决了的是在我们实体Bean中大量的Getter/Setter方法5、web:以web的方式启动，常用。123456789101112131415161718192021222324252627282930dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 简单步骤1、引入数据库驱动-H22、引入jdbc依赖 spring-boot-starter-jdbc3、获取dataSource Bean,打印信息。4、通过/actuator/beans查看bean 获取数据源信息第一步：首先application.properites填写服务需要的配置信息。spring-boot默认使用了hikariCP12345678910111213141516# 端口port= 8081# ..还不了解management.endpoints.web.exposure.include=*spring.output.ansi.enabled=ALWAYS# 数据库信息spring.datasource.url=jdbc:h2:mem:testdbspring.datasource.username=zxyspring.datasource.password=spring.datasource.hikari.maximumPoolSize=5spring.datasource.hikari.minimumIdle=5spring.datasource.hikari.idleTimeout=600000spring.datasource.hikari.connectionTimeout=30000spring.datasource.hikari.maxLifetime=1800000 第二步：在配置创建sql初始化数据库,schema.sql和data.sql确定初始化SQL文件。12spring.dataSource.schemaspring.dataSource.data 创建一个schema.sql文件，里面填写的是创建sql的语句1CREATE TABLE Test (ID INT IDENTITY, BAR VARCHAR(64)); 有了表，然后插入两条数据，创建一个data.sql，里面的内容有12INSERT INTO Test (ID, BAR) VALUES (1, 'aaa');INSERT INTO Test (ID, BAR) VALUES (2, 'bbb'); 第三步：获取数据源信息为了方便程序启动的时候查看获取的配置信息，程序继承 CommandLineRunner并实现run方法，将自己需要显示的内容写进去，就可以在程序启动的时候查看到数据加载的信息了。1234@Override public void run(String... args) throws Exception &#123; &#125; 实现建立连接方法并且获取一个连接123456789101112131415161718192021222324252627282930313233@SpringBootApplication@Slf4jpublic class DemoApplication implements CommandLineRunner &#123; private final static Logger log = LoggerFactory.getLogger(DemoApplication.class); @Autowired private DataSource dataSource; @Autowired private JdbcTemplate jdbcTemplate; @Override public void run(String... args) throws Exception &#123; showConnection(); showData(); &#125; //查看连接信息 private void showConnection() throws SQLException &#123; log.info(dataSource.toString()); Connection conn = dataSource.getConnection(); log.info(conn.toString()); conn.close(); &#125; // 获取一个连接 private void showData() &#123; jdbcTemplate.queryForList("SELECT * FROM FOO") .forEach(row -&gt; log.info(row.toString())); &#125; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 查看运行结果123452019-04-16 23:53:00.714 INFO 14116 --- [ main] com.example.demo.DemoApplication :HikariProxyConnection@656844049 wrapping conn0: url=jdbc:h2:mem:testdb user=ZXY2019-04-16 23:53:00.716 DEBUG 14116 --- [ main] o.s.jdbc.core.JdbcTemplate :Executing SQL query [SELECT * FROM FOO]2019-04-16 23:53:00.779 INFO 14116 --- [ main] com.example.demo.DemoApplication : &#123;ID=1, BAR=aaa&#125;2019-04-16 23:53:00.781 INFO 14116 --- [ main] com.example.demo.DemoApplication : &#123;ID=2, BAR=bbb&#125; 可以通过http://127.0.0.1:8080/actuator/beans查看spring里面的bean]]></content>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-HelloWorld]]></title>
    <url>%2F2019%2F04%2F14%2Fspring-HelloWorld%2F</url>
    <content type="text"><![CDATA[spring项目可以通过https://start.spring.io/来搭建一个spring的初步骨架，接下来通过该网站搭建一个spring项目的helloworld。 进入网站进入https://start.spring.io/。 填写信息选择具体用什么方式来搭建，选择语言，spring框架的版本，还需要填写你的Group和Artifact。具体如下。 导入项目到IDE将生成好的spring项目导入ide，查看目录结构。并运行main函数。 程序入口类如下123456789101112131415161718import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@SpringBootApplication@RestControllerpublic class SpringHelloApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringHelloApplication.class, args); &#125; @RequestMapping("/hello") public String hello()&#123; return "hello"; &#125;&#125; terminal验证请求在terminal输入curl http://127.0.0.1:8080/hello,就会返回hello的结果。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>spring</tag>
        <tag>spring-boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java基本数据类型]]></title>
    <url>%2F2019%2F04%2F08%2Fjava%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[java有八种基本数据类型，分别是 类型 所占字节 位数 取值范围 默认值 对应包装类 byte 1 8 -128~127 0 Byte char 2 12 u0000~uFFF ‘\u0000’ Char short 2 16 －32768～32767 0 Short int 4 32 -2147483648-2147483648 0 Integer float 4 32 -3.40292347E+38-3.40292347E+38 0.0f Float long 8 -9233372036854477808-9233372036854477808 0 Long double 8 64 -1.79769313486231570E+308-1.79769313486231570E+308 0.0d Double boolean 1/8 1 true, false false Boolean]]></content>
      <categories>
        <category>java基本数据类型</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多层感知机实现mnist分类]]></title>
    <url>%2F2019%2F03%2F21%2F%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E5%AE%9E%E7%8E%B0mnist%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;单层感知器（Single Layer Perceptron）是最简单的神经网络。它包含输入层和输出层，而输入层和输出层是直接相连的。下面这个例子取三个输入神经元（A，B，C）并训练它学习逻辑 AB+BC。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# _*_ encoding=utf8 _*_import tensorflow as tfimport tensorflow.contrib.layers as layersn_hidden_1 = 30n_hidden_2 = 256n_classes = 10n_input = 784batch_size =200learning_rate = 0.001max_epoch = 10# 获取mnist数据from tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("./data",one_hot=True)def multilayer_model(x): ''' 建立多层感知机模型 :param x: :return: ''' print(x.shape) fc1 = layers.fully_connected(x,n_hidden_1,activation_fn = tf.nn.relu,scope = 'fc1') print(fc1.shape) fc2 = layers.fully_connected(fc1,n_hidden_2,activation_fn=tf.nn.relu,scope='fc2') print(fc2.shape) out = layers.fully_connected(fc2,n_classes,activation_fn=None,scope='out') return out# [None, 784] [None,10]x = tf.placeholder(tf.float32,[None,n_input],name="X")y = tf.placeholder(tf.float32,[None,n_classes],name='Y')y_ = multilayer_model(x)loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_,labels=y))train = tf.train.AdamOptimizer(learning_rate= learning_rate).minimize(loss)init = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) # 10个batch for epoch in range(10): epoch_loss = 0 #跑完整个数据集合步长 batch_steps = int(mnist.train.num_examples/batch_size) for i in range(batch_steps): batch_x,batch_y = mnist.train.next_batch((batch_size)) _,c = sess.run([train,loss],feed_dict=&#123;x:batch_x,y:batch_y&#125;) epoch_loss += c / batch_steps print('Epoch %0.2d,Loss = %.6f '%(epoch,epoch_loss)) corrent_perdiction = tf.equal(tf.argmax(y_,1),tf.argmax(y,1)) accuracy = tf.reduce_mean(tf.cast(corrent_perdiction,tf.float32)) print('Accuracy:',accuracy.eval(&#123;x:mnist.test.images,y:mnist.test.labels&#125;))]]></content>
      <categories>
        <category>多层感知机</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单层感知机]]></title>
    <url>%2F2019%2F03%2F20%2F%E5%8D%95%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;单层感知器（Single Layer Perceptron）是最简单的神经网络。它包含输入层和输出层，而输入层和输出层是直接相连的。下面这个例子取三个输入神经元（A，B，C）并训练它学习逻辑 AB+BC。]]></content>
      <categories>
        <category>感知机</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逻辑回归]]></title>
    <url>%2F2019%2F03%2F20%2F%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%A4%84%E7%90%86mnist%2F</url>
    <content type="text"><![CDATA[逻辑回归进行分类的主要思想就是：根据现有的数据对分类边界线建立回归公式，对此进行分类。训练分类器就是要找到最佳拟合参数。使用的就是最优化算法。logistic回归的优缺点优点：计算代价不大，易于分类或理解缺点：容易欠拟合，分类精度可能不高 逻辑回归对于一般的分类情况，用一条直接就可以清晰的划分边界。\begin{aligned}h_θ(x) = f(θ_0 + x_1θ_1 + x_2θ_2)\end{aligned}其中θ用向量表示为[3,1,1]，则当$-3+x_1+x_2$大于等于0，即$x_1+x_2$大于等于3 时，模型将预测 y=1，反之，预测为0。由此，可以得到分界线如下图所示。但是对于线性不可分的情况，我们就无法用一条直线去区分不同的类别。此时，引入了逻辑回归就是为了解决线性不可分的情况。对于分类我们需要的函数应该是能接受所有的输入然后预测出类别，比如，在两个类别的情况下，改函数会输出0或者1，对此，我们可以用sigmoid函数，sigmoid的公式为：\begin{aligned}f(z) = \frac{1}{1 + e^{-z}}\end{aligned}sigmoid函数图像的理解。当x=0时，sigmoid函数值对应的是0.5，随着x的增大，sigmoid函数值也随之增大，无限趋近与1，随着x的减小，sigmoid函数值随之减小，无限趋近于0。所以，sigmoid函数的到的值是一个0到1反之的数，任何大于0.5的数据将被分为1类，小于0.5的数据将被分为0类。，所以，sigmoid也可以被看做为一种概率估计。有了分类器的函数形式之后，我们就需要找到最佳的回归系数。 基于最优化算法的最佳回归系数确定sigmoid函数的输入记为z，有下面的公式得出：\begin{aligned} z = w_0x_0+w_1x_1+w_2x_2+…..+w_nx_n\end{aligned}采用向量的写法，该公式就表示为\begin{aligned}z = w^Tx\end{aligned}该公式表示将这两个数值向量的对应元素相乘然后全部加起来的z值，其中向量x是分类器的输入数据，向量w是我们需要的最佳参数集，为了寻找到最佳参数，此处可以采用梯度下降算法。 梯度下降算法对于线性回归，我们知道它的代价函数为 J(\Theta ) = \frac{1}{2m}\sum_{i=1}^{m}(h_\Theta (x^{(i)})-y^{(i)})^2由此，我们可以定义逻辑回归的损失函数为 J(\Theta ) = \frac{1}{m}\sum_{i=1}^{m}(Cost(h_\Theta (x^i),y^i)将概率取对数，函数的单调性保持不变，那么逻辑回归的代价函数可以表示为 Cost(h_\Theta (x),y) = \left\{\begin{matrix} log(h_\Theta (x)) \quad (if \quad y = 1)& & \\ log(1-h_\Theta (x)) \quad (if\quad y = 0)& & \end{matrix}\right.上面两个式子也就是在样本x和参数θ的情况下，样本x属于正样本（y=1)和负样本（y=0)的条件概率，但是这是非常理想的情况下，我们并不是只有把sigmoid值为1才分为1类，把sigmoid值为0才分为0类，而是把sigmoid值大于0.5分为1类，把sigmoid值小于0.5分为0类。 逻辑回归假设因为y值非0即1，所以我们用指数的方式将这两个公式合并成一个公式。 P(y|x;\Theta ) = h_\Theta (x)^y*(1-h\Theta (x))^(1-y)由此可以得到似然函数 L(\Theta ) = \prod_{i=1}^{m} P(y_i|x_i;\Theta ) = \prod_{i=1}^{m}(h_\Theta (x_i))^{(y_i)}(1-h_\Theta (x_i))^{(1-y_i)}取对数，简化运算 l(\Theta ) = logL(\Theta ) = \sum_{i=1}^{m}(y_ilogh_\Theta (x_i) + (1-y_i)log(1-h_\Theta (x_i)))合并出来的这个新的函数称之为cost函数，也为代价函数(Cost Function)。此时可以用梯度上升法求极大释然函数，求出来的$\Theta$就是最佳的参数。但是我们希望在参数更新或衡量模型优劣时是需要一个能充分反映模型表现误差的代价函数，希望损失函数越小越好,所以我们取上面对数函数概率的相反数。此时就可以通过梯度下降法去更新参数。那么逻辑回归的损失函数为 J(θ) = - \frac{1}{m} \sum_{i=1}{m}(Cost(h_θx^{(i)},y^{(i)}))\\ =- \frac{1}{m} [\sum_{i=1}^{m}y^{(i)}log(h_θ(x^{(i)})) + (1-y^{(i)}log(1-h_θ(x^{(i)}))]其中，m为样本的总数，y(i)表示第i个样本的类别，x(i)表示第i个样本，需要注意的是θ是多维向量，x(i)也是多维向量。对J(θ)求极小值，就得到了θ的估计值。得到损失函数之后，就可以通过梯度下降法去反复更新每一个参数。梯度下降法为： \Theta _j := \Theta _j - \alpha \frac{\partial J(\Theta)}{\partial \Theta _j}求导后得到 \Theta _j = \Theta _j - \alpha \frac{1}{m}\sum_{i=1}^{m}(h_\Theta (x^{(i)}) - y^{(i)})(x_j)^{(i)}具体的推导过程参见链接虽然得到的梯度下降算法表面上看上去与线性回归的梯度下降算法一样，但是这里的 $h_θ(x)=f(θ^Tx)$与线性回归中不同，所以实际上是不一样的。另外，在运行梯度下降算法之前，进行特征缩放依旧是非常必要的。除了梯度下降算法以外，还有一些常被用来令代价函数最小的算法，这些算法更加复杂和优越，而且通常不需要人工选择学习率，通常比梯度下降算法要更加快速。这些算法有：共轭梯度，共轭梯度法 BFGS (变尺度法) 和L-BFGS (限制变尺度法)。 梯度下降法求最佳参数梯度下降法的基本思想是：找到某函数的最小值，最好的方式就是按照该函数的梯度方向寻找，因为梯度的方向总是验证函数值变化最快的方向，这儿将步长记为$\alpha$,用向量的表示方法，梯度下降的算法的迭代公式为\begin{aligned}w:= w - \alpha\frac{\partial f(w)}{\partial w}\end{aligned}该公式会一直被执行，直到达到某种条件之后，比达到指定次数之后或者允许误差范围之内。对于函数f(x,y)，它的梯度由下面公式表示：\begin{aligned}\Delta f(x,y) = \binom{\frac{\partial f(x,y)}{\partial x}}{\frac{\partial f(x,y)}{\partial y}}\end{aligned}这个梯度着要向沿x的方向移动$\frac{\partial f(x,y)}{\partial x}$,沿y的方向移动$\frac{\partial f(x,y)}{\partial y}$,其中，函数f(x,y)必须要在待计算的点有定义并且可微。根据以下伪代码实现梯度下降法每个回归系数初始化为1重复R次 计算整个数据集的梯度 使用alpha * gradient更新回归系数的向量返回回归系数 多元分类我用三种不同的符号来代表三个类别，问题怎样在给出的三种类别数据集上得到一个学习算法，从而进行分类?我们现在已经知道如何进行二元分类，可以使用逻辑回归，对于直线或许你也知道，可以将数据集一分为二为正类和负类。用一对多的分类思想，我们可以将其用在多类分类问题上,现在我们有一个训练集，好比上图表示的有三个类别，我们用三角形表示 y=1，方框表示 y=2，叉叉表示 y=3。我们下面要做的就是使用一个训练集，将其分成三个二元分类问题。我们先从用三角形代表的类别1开始，实际上我们可以创建一个，新的”伪”训练集，类型2和类型3定为负类，类型1设定为正类。就变成一个二分类的问题了。12345678910111213141516171819202122232425262728293031323334353637# _*_ encoding=utf8 _*_import codecsimport numpy as npdef loadData(): dataList = [] labelList = [] with codecs.open("./data/testSet.txt","r","utf-8") as fr: for index,line in enumerate(fr): lineArr = line = line.strip().split("\t") dataList.append([1.0, float(lineArr[0]), float(lineArr[1])]) labelList.append(int(lineArr[2])) return dataList,labelListdef sigmoid(X): return 1.0/(1+np.exp(-X))def gradAscent(dataMaxIn,classlabels): dataMatrix = np.mat(dataMaxIn) labelMat = np.mat(classlabels).transpose() m,n = np.shape(dataMatrix) alpha = 0.001 maxCycle = 500 weights = np.ones((n, 1)) for k in range(maxCycle): h = sigmoid(dataMatrix * weights) error = (labelMat -h) weights = weights + alpha*dataMatrix.transpose()*error return weightsif __name__ == '__main__': dataArr,labelMat = loadData() weights = gradAscent(dataArr,labelMat) print(weights) 数据下载地址loadData函数就是加载数据，每行的前两个值是X1,X2,第三个值就是对应的类别。同时为了计算，将X0的值设置为1,gradAscent就是梯度上升法，dataMatrix是一个二维数组，一共有100行，每一行就是每一个训练样本，每一列则表示不同的特征，特征目前包括了文件里面的x1,x2还有为了方便计算添加的x0,所以dataMatrix是一个100*3的矩阵，np.mat()是将序列转为np的二维数组，np.transpose()是将数组转置。变量alpha是步长，maxCycle是迭代的次数。训练完成就可以返回回归系数。weights的初始化权重都是1，shape=(3,1),error就是正确分份额里结果和预测的分类结果的损失值。该损失值用于更新权重weightslabelMat是一个[100,1]的矩阵，m=100,n=3这两个可以理解为dataMatrix的行和列。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用逻辑回归对mnist数据集进行分类预测12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# _*_ encoding=utf8 _*_import tensorflow as tf# mnist数据集大小为 [55000，784] 的 mnist.train.images 和大小为 [55000，10] 的 mnist.train.labelsfrom tensorflow.examples.tutorials.mnist import input_datamnist = input_data.read_data_sets("MNIST_data/",one_hot=True)x = tf.placeholder(tf.float32, [None, 784], name = 'X')y = tf.placeholder(tf.float32, [None, 10], name = 'Y')max_epochs = 1000batch_size = 100# 初始化权重和偏置W = tf.Variable(tf.zeros([784, 10]), name="W")b = tf.Variable(tf.zeros([10]), name="b")# 创建模型with tf.name_scope("wx_b") as scope: # softmax通常用于解决多分类的问题，把输出值归一化为到每一类的概率，所有的概率之和呢为1，sigmoid一般解决二分类问题 y_ = tf.nn.softmax(tf.matmul(x, W) + b)# 定义交叉损失熵with tf.name_scope('cross_entropy') as scope: loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_)) tf.summary.scalar('cross-entropy', loss)# 选择使用梯度下降优化器，学习率设置为0.01with tf.name_scope("train") as scope: optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)init = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) for epoch in range(max_epochs): batch_xs,batch_yx = mnist.train.next_batch(batch_size) sess.run([optimizer,loss],feed_dict=&#123;x:batch_xs,y:batch_yx&#125;) # 当axis=1时，以行为单位 找出行中最大的值得索引，然后比较预测出来的索引和实际最大的索引是否一致 correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1)) accuracy = tf.reduce_mean(tf.cast(correct_prediction,"float")) print(sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y:mnist.test.labels&#125;))]]></content>
      <categories>
        <category>逻辑回归</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多元线性回归]]></title>
    <url>%2F2019%2F03%2F20%2F%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在吴恩达的机器学习的视频中，通过真实的一些房价的数据去预测房价。除了房子的面积之外，还有房间数楼层等因素，都会影响房子的价格，对此，可根据多元回归函数从房子多方面的情况对价格进行预测。对这些变量特征描述为$(x_1,x_2,…,x_n）$。 多元线性回归从单变量线性回归我们可以推出，多变量线性回归的函数可以表示为\begin{aligned}h_\Theta (x) = \Theta _0 + \Theta _1x_1 + \Theta _2x_2 + … + \Theta _nx_n\end{aligned}还是和之前一样，将$x_0$设置为1，此时模型的参数就是一个n+1维的向量 ，任何一个训练实例也都是n+1维的向，特征矩阵X的维度是 m*(n+1)。因此公式可以简化为 h_\Theta (x) = \Theta ^T x其中$θ^T$表示参数矩阵θ的转置矩阵。从之前的单线性回归可以得到，多线性回归的损失函数为 J(\Theta _0\Theta _1...\Theta _n) = \frac{1}{2m}*\sum_{i=1}^{m}(h_\Theta (x^i)-y^i)^2多元线性回归表示为： h_\Theta (x) = \Theta ^T x = \Theta _0x_0 + \Theta _1x_1 + \Theta _2x_2 + ... + \Theta _nx_n同时，和单变量线性回归一样，我们需要根据梯度下降找到使得代价函数最小的参数。该损失函数的梯度下降公式。 \Theta _j:=\Theta _j - \alpha \frac{\partial J(\Theta _0,\Theta _1...\Theta _n)}{\partial \Theta _j}也就是 \Theta _j =\Theta _j - \alpha \frac{\partial }{\partial \Theta _j}\frac{1}{2m}\sum_{i=1}^{m}(h_\Theta (x^{(i)})-y^{(i)})^2对其进行求导 \Theta _j:=\Theta _j - \alpha \frac{1}{m}\sum_{i=1}^{m}(h_\Theta (x^{(i)})-y^{(i)})(x_j^{(i)})对于$θ_0,θ_1…θ_n$，我们都有上述梯度下降去更新θ的值，并且所有的参数进行同时更新。直到函数收敛。 特征缩放对多维特征的时候，时常会发现这些特征的尺度相差很大，他们没有一个统一的单位，比如：房屋的尺寸可能是0-2000平凡英尺，但是房间的数量就1-5间，这样的话代价函数打的等高线图就呈现椭圆形，很难收敛，一般解决的办法是将这些特征缩放到-1到1。对于数据的均值归一化，可以下面的方法第一种\begin{aligned}X = \frac{X - \mu _n}{S_n}\end{aligned}其中是$\mu _n$平均值，$S_n$是标准差，分母用最大值减去最小值也是可以的，$X_1 = \frac{size - 1000}{2000} $,$X_2 = \frac{roomnum - 2}{5}$。 代码实现python12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576# _*_ encoding=utf8 _*_import numpy as npimport matplotlib.pyplot as pltimport codecsdef loadData(): ''' 加载数据 :param filename: :return: ''' data = [] # 两个特征，第一个是房子大小，第二个是房间数 with codecs.open("./data/ex1data2.txt","r","utf-8") as fr: for index,line in enumerate(fr): lineArr = line.strip().split(",") temp = [] for i in range(3): temp.append(float(lineArr[i])) data.append(temp) return datadef dataNormalize(train_data): ''' 均值归一化 :param train_data: :return: ''' mean = np.mean(train_data, axis=0) # 对列求均值 std = np.std(train_data,axis=0) norm_data = train_data - mean / std return norm_datadef costFuntion(X_test,Y_test,theta): shape = X_test.shape[0] return 0.5*np.sum(np.square(X_test.dot(theta) - Y_test))/shapedef gradDescent(X_test,Y_test,theta): iters = 1000 alpha = 0.01 loss = [] num_X = X_test.shape[0] # 47 for i in range(iters): theta = theta - alpha* X_test.T.dot(X_test.dot(theta) - Y_test) / num_X cost = costFuntion(X_test, Y_test, theta) loss.append(cost) return theta, lossdata = loadData()data = np.array(data)print(data.shape)X = data[:,:-1] # 两个特征Y = data[:,-1:] #norm_data = dataNormalize(X) # 归一化数据num_shape = X.shape[0]ones = np.ones((num_shape, 1))X = np.hstack((ones, norm_data))# 3 = data.shape[1]print(X.shape[1])w = np.zeros((X.shape[1],1))# X = [97,2] Y[97,1] 得到了最优theta参数theta,loss = gradDescent(X,Y,w)print(theta)#查看损失函数的变化gradDescentplt.plot(loss)plt.xlabel('iter')plt.ylabel('loss')plt.show() tensorflow123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596# _*_ encoding=utf8 _*_import tensorflow as tfimport numpy as npimport matplotlib.pyplot as pltdef normalize(X): ''' 数据归一化，由于每个数据的变化范围不同，比如面积可能在50-300之间，但是里市中心的距离就是0-1000 采用归一化的方法，归一化原始数据经过数据标准化处理后，使得各指标处于同一数量级，进行综合对比评价。 :param X: :return: 归一化数据之后的矩阵 ''' mean = np.mean(X) # np.mean(a, axis=0) # axis=0，计算每一列的均值 axis=1，计算每一行的均值 std = np.std(X) # 计算全局标准差 np.std(a, axis=0) # axis=0计算每一列的标准差 axis=1计算每一行的标准差 X = (X - mean) / std # 矩阵X每一个元素都减去平均值 return Xdef append_bias_reshape(features,labels): ''' 该函数的作用是添加一个额外的固定输入值将权重和偏置结合起来 :param features: :param labels: :return: ''' m = features.shape[0] n = features.shape[1] # np.r_是按列连接两个矩阵，就是把两矩阵上下相加，要求列数相等。 # np.c_是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等。 # 对特征矩阵进行处理，在特征矩阵每一行前面都补上一个1，特征矩阵从[m,n]扩展为[m,n+1] x = np.reshape(np.c_[np.ones(m),features],[m, n+1]) y = np.reshape(labels,[m,1]) return x, y# 获取波士顿房价的数据data = tf.contrib.learn.datasets.load_dataset('boston')X_train,Y_train = data.data,data.target# 归一化数据X_train = normalize(X_train)# 将权重和偏置结合起来 这种方式明显可以加快运算X_train,Y_train = append_bias_reshape(X_train,Y_train)m = len(X_train) #训练集样本数 506n = 13 + 1 #特征数加 偏移 X_train.shape[0]# n = 13# 声明占位符X = tf.placeholder(dtype = tf.float32,shape=[m,n],name = "X")Y = tf.placeholder(tf.float32,name = "Y")# 初始化权重w# b = tf.Variable(tf.random_normal([m]))w = tf.Variable(tf.random_normal([n,1]))# X w叉乘[m，n+1] [n+1,1] 相当于刚刚用1补充的那个位置，1乘以任何数等于任何数，起到一个偏置的作用# Y_ = tf.add(tf.matmul(X ,w), b)Y_ = tf.matmul(X ,w)loss = tf.reduce_mean(tf.square(Y - Y_,name = "loss"))optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize((loss))init = tf.global_variables_initializer()total = []with tf.Session() as sess: sess.run(init) writer = tf.summary.FileWriter("line_recogniton_graphs", sess.graph) for i in range(500): for x,y in zip(X_train,Y_train): _,_loss = sess.run([optimizer,loss],feed_dict=&#123;X:X_train,Y:Y_train&#125;) total.append(_loss) print('epoch &#123;0&#125;: Loss &#123;1&#125;'.format(i,_loss)) writer.close() # w_value,b_value = sess.run([w, b]) w_value = sess.run([w]) print(w_value) # print(b_value) # 查看训练过程损失的变化 plt.plot(total) plt.show() # 通过模型学习到的参数来进行预测 N = 500 X_test = X_train[N,:] X_test = X_test.reshape(1,n) predict = np.matmul(X_test,w_value).round(1) # predict = np.matmul(X_test,w_value) + b_value[0] print(predict) print("预测房价为：$&#123;0&#125; 真实房价为: $&#123;1&#125;".format(predict*1000, Y_train[N]*1000))]]></content>
      <categories>
        <category>线性回归</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单线性回归]]></title>
    <url>%2F2019%2F03%2F19%2F%E7%AE%80%E5%8D%95%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在吴恩达的机器学习的视频中有一个房价预测问题，通过真实的一些房价的数据去预测房价。对此，可以根据y=wx+b回归函数从房子的面积对价格进行预测。现在有一批波士顿房价的数据，其对房价的影响因素有13个，我们取出第五个房价的大小作为影响因素去预测房价。 简单线性回归查看一下数据的分布对于房价预测问题，我们需要建立一个数学模型去拟合这些数据，使得不同的房子的面积对应不同的房价。给出的数学模型为\begin{aligned}y = θ_0 + θ_1x\end{aligned}对于$θ_0$和$θ_1$称之为模型参数，已知x，也就是求得$θ_0$和$θ_1$我们就可以知道对应面积的房子的价格。当得到最佳的$θ_0$和$θ_1$之后，也就得到了最拟合实际的房价y。那么如何求得最合适的$θ_i$呢，根据上面的散点图作为训练数据，我们选择的参数决定了我们得到的直线相对于我们的训练集的准确程度，模型所预测的值与训练集中实际值之间的差距越小，则代表我们获取的$θ_i$越好。所以在线性回归中我们要解决一个最小化的问题，而*模型所预测的值与训练集中实际值之间的差距（下图中蓝线所指）就是建模误差我们的目标便是选择出可以使得建模误差的平方和能够最小的模型参数，即使得代价函数（公式如下）最小。 J(\Theta _0,\Theta _1) = \frac{1}{2m}\sum_{i=1}^{m}(h_\Theta(x^{(i)}) - y^{(i)} )^2m是样本总数，1/2m是将这个表达式简化。\begin{aligned}h_\Theta (x^i) = \Theta _0 + \Theta _1x\end{aligned}所以这个问题就是：找到能使我们训练集中的预测值和真实值的差的平方的和的1/2m最小的$0_1$和$0_0$值。上述公式也成为平方误差函数，也就我们所需要用到的损失函数。当$J(θ_0,θ_1)$越小，也就是反应了预测的房价和真实房价的误差也就越小，我们通过用梯度下降的方法去求$J(θ_0,θ_1)$得最小值。 梯度下降法求最小值度下降背后的思想是：开始时我们随机选择一个参数的组合（θ0,θ1,…,θn），计算代价函数，然后我们寻找下一个能让代价函数值下降最多的参数组合。我们持续这么做直到到到一个局部最小值（local minimum），因为我们并没有尝试完所有的参数组合，所以不能确定我们得到的局部最小值是否便是全局最小值（global minimum），选择不同的初始参数组合，可能会找到不同的局部最小值。想象一下你正站立在山的这一点上，站立在你想象的公园这座红色山上，在梯度下降算法中，我们要做的就是旋转360度，看看我们的周围，并问自己要在某个方向上，用小碎步尽快下山。这些小碎步需要朝什么方向？如果我们站在山坡上的这一点，你看一下周围，你会发现最佳的下山方向，你再看看周围，然后再一次想想，我应该从什么方向迈着小碎步下山？然后你按照自己的判断又迈出一步，重复上面的步骤，从这个新的点，你环顾四周，并决定从什么方向将会最快下山，然后又迈进了一小步，并依此类推，直到你接近局部最低点的位置。梯度下降的公式 \Theta _j := \Theta _j - \alpha \frac{\partial J(\Theta _0,\Theta _1)}{\partial \Theta _j} (j = 0 ,j = 1)其中α是学习率（learning rate），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数($θ0$,$θ_1$)减去学习速率乘以代价函数的导数。所以梯度下降中，我们要更新$θ_0$和$θ_1$，当 j=0 和 j=1 时，就会产生更新，所以你将更新$Jθ0$和$J_θ1$。如果你要更新这个等式，你需要同时更新θ0和θ1，也就是 \Theta _0 := \Theta _0 - \alpha \frac{\partial J(\Theta _0,\Theta _1)}{\partial \Theta _0} (j = 0 )\\ \Theta _1 := \Theta _1 - \alpha \frac{\partial J(\Theta _0,\Theta _1)}{\partial \Theta _1} (j = 1 )那么接下来对θ赋值，使得J(θ)按梯度下降最快方向进行，一直迭代下去，最终得到局部最小值。其中α是学习率。它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大。由于导数总是变化最快的方向，所以对$J(θ)$来说，也就是它变化最快的方向，对于J(θ),我们知道它的图像大致是这样。梯度下降法的更新规则求导的目的，也就是取的该点的斜率，就是红色直线与函数相切于这一点，这条刚好与函数曲线相切的直线的斜率正好是这个三角形的高度除以这个水平长度，现在，这条线有一个正斜率，也就是说它有正导数，因此会得到得到的新的$θ_1$，$θ_1$更新后等于$θ_1$减去一个正数乘以α。但是步长α不能太大也不能太小如果α太小了，也是就学习速率太小，这样就需要很多步才能到达最低点。如果α太大，梯度下降法可能会越过最低点，甚至可能无法收敛，甚至发散。如果$θ_1$已经在局部最低点了，这时候求出来的斜率为0，那么它使得$θ_1$不再改变，也就是新的$θ_1$等于原来的$θ_1$,所以这个时候梯度函数就什么都没有做。同时呢，当α固定，斜率越大，$θ_1$更新的幅度也就越大，也就走的越快，斜率越小，更新幅度就小，也就走的慢，这个时候就有可能达到局部最优解。也就是在梯度下降法中，当接近局部最低点时，梯度下降法会自动采取更小的幅度。没有没有必要再这种情况再去减小α。梯度下降算法以用来最小化任何代价函数J，不只是线性回归中的代价函数J。现在运用梯度下降算法去求线性回归模型的最优解了。梯度下降算法 \begin{aligned}\Theta _j := \Theta _j - \alpha \frac{\partial J(\Theta _0,\Theta _1)}{\partial \Theta _j} (j = 0 ,j = 1)\end{aligned} 线性回归函数\begin{aligned}h_\Theta (x) = \Theta _0 + \Theta _1x\end{aligned}线性回归的损失函数 J(\Theta _0,\Theta _1) = \frac{1}{2m}\sum_{i=1}^{m}(h_\Theta(x^{(i)}) - y^{(i)} )^2对损失函数求导，用梯度下降法去更新$θ_j$的值当j=0，求导 \frac{\partial }{\partial \Theta _0}J(\Theta _0,\Theta _1) = \frac{1}{m}\sum_{i=1}^{m}(h_\Theta (x^{(i)})-y^{(i)})当j=1，求导 \frac{\partial }{\partial \Theta _1}J(\Theta _0,\Theta _1) = \frac{1}{m}\sum_{i=1}^{m}(h_\Theta (x^{(i)})-y^{(i)})(x^{(i)})由于在梯度下降的每一步中，我们都用到了所有的训练样本，所以也叫批量梯度下降。 对于线性回归，我们可以给$0_0$乘以一个常数。那么公式就变成下面这样 h_\Theta (x) = \Theta _0 x_0+ \Theta _1 x_1(x_0 = 1)那么对于$x_i$，它的梯度下降就变成如下 \Theta _j:=\Theta _j - \alpha \frac{1}{m}\sum_{i=1}^{m}(h_\Theta (x^{(i)})-y^{(i)})(x_j^{(i)})代码实现python1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980# _*_ encoding=utf8 _*_import numpy as npimport matplotlib.pyplot as pltimport codecsdef loadData(): ''' 加载数据 :param filename: :return: ''' data = [] with codecs.open("./data/ex1data1.txt","r","utf-8") as fr: for index,line in enumerate(fr): temp_label = [] temp_train = [] lineArr = line.strip().split(",") temp = [] for i in range(2): temp.append(float(lineArr[i])) data.append(temp) return datadef costFuntion(X_test,Y_test,theta): shape = X_test.shape[0] # 97 return 0.5*np.sum(np.square(X_test.dot(theta) - Y_test))/shapedef gradDescent(X_test,Y_test): iters = 1000 alpha = 0.01 loss = [] theta = np.array([[0.001],[0.001]]) num_X = X_test.shape[0] #97 for i in range(iters): theta = theta - alpha* X_test.T.dot(X_test.dot(theta) - Y_test) / num_X cost = costFuntion(X_test, Y_test, theta) loss.append(cost) return theta, lossdata = loadData()data = np.array(data)print(data)print(data.shape)X = data[:,:-1]Y = data[:,-1:]# 查看数据plt.scatter(X,Y,color='red')plt.xlabel('train')plt.ylabel('label')plt.show()num_shape = X.shape[0]ones = np.ones((num_shape, 1))# 补1data[:,:-1]X = np.hstack((ones,X))print(Y) #theta0 theta1w = np.zeros((2,1))# X = [97,2] Y[97,1] 得到了最优theta参数theta,loss = gradDescent(X,Y)print(theta)#查看拟合的曲线plt.scatter(X[:,1],Y,color = 'red')plt.xlabel('X')plt.ylabel('y')plt.plot(X[:,1],X.dot(theta),'-',color = 'yellow')plt.show()#查看损失函数的变化plt.plot(loss)plt.xlabel('iter')plt.ylabel('loss')plt.show() 拟合直线损失函数的变化 tensorflow12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273# _*_ encoding=utf8 _*_# 导入需要的python库import tensorflow as tfimport matplotlib.pyplot as plt# 获取波士顿房价数据集，并且房间的大小去预测波士顿房价data = tf.contrib.learn.datasets.load_dataset('boston')X_train,Y_train = data.data[:,5],data.target # 取出第五个因数作为因变量# 查看取出来的训练数据和形状，[506,1]print(X_train)print(X_train.shape)# 获取多少个训练数据样本n_sample = len(X_train)# 为训练数据声明占位符X = tf.placeholder(tf.float32,name = "X")Y = tf.placeholder(tf.float32,name = "Y")# 创建权重和偏置项并且都置为0b = tf.Variable(0.0)w = tf.Variable(0.0)# 定义用于房价预测的线性回归模型line_model = X * w + b# 计算预测的房价和取出来的target的差值，作为损失loss = tf.square(Y - line_model,name= "loss")# 采用梯度下降优化器优化权重optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize((loss))init = tf.global_variables_initializer()total = []with tf.Session() as sess: sess.run(init) # 声明图 writer = tf.summary.FileWriter("graphs", sess.graph) # 100 迭代 for i in range(100): total_loss = 0 for x,y in zip(X_train,Y_train): # 这儿计算出来的是每一次迭代每一个训练数据的预测值和真实值的损失， _,_loss = sess.run([optimizer,loss],feed_dict=&#123;X:x,Y:y&#125;) # 将每一次损失相加 total_loss += _loss # 得到每一次迭代的损失 total.append(total_loss / n_sample) print('Epoch &#123;0&#125;: Loss &#123;1&#125;'.format(i,total_loss/n_sample)) writer.close() # 查看训练的参数 b_value,w_value = sess.run([b,w]) print(w_value) print(b_value) # 查看结果 Y_pred就是用训练的参数得到的线性回归模型 Y_pred = X_train * w_value + b_value print("train finished") # 蓝色的数原始数据，红色的线就是训练出来的线性模型 plt.plot(X_train,Y_train, "boston", label = "data") plt.plot(X_train,Y_pred,'r',label = "predicted data") plt.legend() plt.show() # 查看训练过程中loss的变化 plt.plot(total) plt.show() 参考吴恩达机器学习课程]]></content>
      <categories>
        <category>线性回归</category>
      </categories>
      <tags>
        <tag>tensorflow</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java内存管理]]></title>
    <url>%2F2019%2F03%2F04%2Fjava%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[java的内存管理都是由jvm完全负责的,垃圾回收器会去回收无用的对象占据的内存资源，从而避免了编码人员自己对内存进行管理（相对比c,自己new的对象必须自己delete),虽然垃圾回收器管理内存给编码人员带来了很大的方便，但是java中的垃圾回收不是能及时去释放的，所以有的时候还是得要编码人员自己去释放内存，对部分对象进行合理的管理，从而避免了资源过度占用导致的资源消耗。 java中的内存分布由图可以看见java的内存区域主要划分为以下几个部分。程序计数器，java虚拟机栈，本地方法栈，java堆，方法区 程序计数器程序计数器是一个记录着当前线程所执行的字节码的行号指示器。java代码编译后的字节码在未经过JIT（实时编译器）编译前，是通过字节码解释器进行解释执行的，简单的工作原理是，解释器读取装载如内存的字节码，按照顺序读取字节码指令，读取一个指令后，将改指令翻译成固定的动作，并根据这些操作进行顺序、分支、循环等流程。通过上面的描述是不是发现这个程序计数器有些多余，你可能会觉得程序按照指令顺序的执行下去，即使是分支跳转这样的流程，挑转到特定的指令出按照顺序执行就可以保证程序的顺序执行，但是这只是程序永远只有一个线程的情况，不需要程序计数器来记录执行的位置，但是JVM是多线程的，JVM的多线程是通过时间片轮转法来实现的，简单来说，就是某一个线程在执行过程中可能会因为时间片耗尽而被挂起，另一个线程获取到时间片开始执行，当被挂起的线程重新获得时间片后，将从挂起的状态继续执行，这个时候，就必须知道该该线程上次执行到什么位置，程序计数器就是在JVM中记录某一个线程的字节码执行位置，所以我们可以知道程序计数器的一个特点，就是线程隔离，也就是每一个线程都拥有一个自己的程序计数器。 什么是JIT技术？通常javac将程序源码编译，转换成java字节码，JVM通过解释字节码将其翻译成相应的机器指令，逐条读入，逐条解释翻译。非常显然，经过解释运行，其运行速度必定会比可运行的二进制字节码程序慢。为了提高运行速度，引入了JIT技术。在执行时JIT会把翻译过的机器码保存起来，已备下次使用，因此从理论上来说，采用该JIT技术能够，能够接近曾经纯编译技术。 程序计数器的特点?1、线程隔离，每一个线程都有属于自己的独立计数器2、执行java程序的时候，程序计数器是有值的，该值记录的是正在执行的字节码指令的地址3、执行native本地方式的时候，程序计数器为空（undefined)，native方式是java通过JNI直接调用本地的C/c++库，java是通过JNI直接调用到C/C++里面具体的操作，所以该方法是C/C++实现的，而不是通过java实现，所以无法产生相应的字节码，是不由JVM决定的。4、程序计数器占用的内存很小，在进行JVM内存计算时，可以忽略不计5、程序计数器，是唯一一个在java虚拟机规范中没有任何OutOfMemoryError的区域。 为什么说程序计数器没有任何OutOfMemoryError的区域？如果线程执行的是一个java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址。如果正在执行的Native方法，这个计数器的值就为空（undefined)，此内存区域是唯一一个在java虚拟机规范中没有规定任何OutofMemoryError情况的区域。 java的虚拟机栈java虚拟机栈同程序计数器一样，是线程私有的，生命周期和线程相同。虚拟机栈描述的是Java方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈幁，用来存储局部变量表，操作栈，动态链接，方法出口等信息。每个方法从调用直到执行完成的过程，都对应一个栈幁在虚拟机栈中从入栈到出栈的过程。 在编译程序代码的时候，栈帧需要多大的局部变量表，多深的操作数栈都已经完全确定了，并且写入到方法表的code属性中，因此一个栈帧需要分配多少内存，不会受到运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。一个线程中的方法调用链路可能会很长，很多方法都处于同时执行的状态。对于执行引擎来说，在活动线程中，只有处于栈顶的栈帧才是有效的，称为当前栈帧，与这个栈帧相关联的方法称为当前方法。执行引擎运行的所有字节码指令只针对当前栈帧进行操作，在概念模型上，典型的栈帧结构如图所示： 在工作和学习过程中，java程序员会把java内存分为堆内存和栈内存，这种划分方式只能说明大多数程序员最为关注的与对象分配关系最为密切的区域是这两块，实际的划分要复杂的多。这里所说的栈就是java虚拟机栈，更准确的说应该是虚拟机栈中的局部变量表。 局部变量表是一组变量值存储空间，用以存储方法参数与方法内部定义的局部变量。在Java程序被编译为Class文件时，就在方法的Code属性的max_locals数据项中确定了该方法所需的局部变量表的最大容量。 局部变量表的容量以变量槽（Variable Slot，下称Slot）为最小单位，虚拟机规范中并没有明确指出一个slot占应用内存的大小，只是很有导向性的指出一个slot都应该可以存放一个byte、short、int、float、char、boolean、对象引用（reference）、returnAddress(指向一个字节码指令的地址)，这8种类型的数据，都可以使用32位或者更小的空间去存储，但这种描述与明确指出“每个slot占用32位的内存空间”有一些区别，它允许slot的长度可以随着处理器、虚拟机、操作系统的不同而发生变化。只要保证即使在64位虚拟机下使用64位内存去实现slot，虚拟机仍需要使用对齐和补白的方式使之在外观上看起来和32位下一致。 一个slot可以存放一个32位的数据类型，Java中占用32位以内的数据类型有byte、short、int、float、char、boolean、reference(对象引用，java虚拟机没有规定reference类型的长度，它的实际长度与32位还是64位虚拟机有关，如果是64位虚拟机，他的长度还与是否开启某些对象指针的压缩优化有关)、returnAddress 8种数据类型。第7种refrence类型表示一个对象实例的引用，虚拟机规范中既没有说明长度也没有说明引用应有怎样结构。但一般情况来说，虚拟机通过这个引用应该至少做到两点，一是通过这个引用直接或间接的查找到对象在java堆中数据存放的起始位置索引，而是通过此引用查找对象所属数据类型再方法区存储的类型信息，否则无法实现java语言规范中定义的语法约束。returnAddress执行一条字节码指令的地址，为字节码指定jsr、jsr_w和ret服务的，很古老的java虚拟机曾经使用这几条指令来实现异常处理，现在已经由异常表代替。 在java虚拟机规范中，对这个内存区域规定了两种异常，如果线程请求的栈深度大于虚拟机所允许的深度，会抛出StockOverError异常；如果虚拟机栈可以动态扩展，如果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。 本地方法栈本地方法栈本地方法栈与虚拟机栈发挥的功能非常类似，只是虚拟机栈为虚拟机执行java方法而服务，而本地方法栈为虚拟机执行native方法而服务。虚拟机规范中对本地方法栈中使用的方法的语言、使用方式、与数据结构并没有强制规定。因此具体的虚拟机可以有各自的实现方式。甚至有的虚拟机把本地方法栈和虚拟机栈合二为一，比如Sun HotSpot 虚拟机。与虚拟机栈一样，本地方法栈也会抛出StackOverflowError和OutOfMemoryError异常。对于一个运行中的java程序而言，可能会用到跟本地方法相关的数据区域。当一个线程调用本地方法时，它就进入一个全新的不受虚拟机限制的全新世界。本地方法也可以通过本地方法接口调用虚拟机的运行时数据区域。本地方法本质上依赖于实现，虚拟机的实现者可以自由得决定通过什么机制让java程序调用本地方法。任何本地方法接口都会使用某种本地方法栈。当虚拟机调用java方法时，虚拟机会创建一个栈帧并且压入虚拟机栈；当虚拟机调用本地（native）方法时，虚拟机不会创建新的栈帧，虚拟机栈会保持不变，虚拟机只是简单的动态连接并直接调用相关的本地方法。如果本地方法接口是c连接模型的话，它的本地方法栈就是c栈。当c程序调用一个c函数时，传递给该函数的参数以相应的顺序压入栈，它的返回值以确定的方式返回给调用方。这就是虚拟机实现中本地方法栈的行为。也有一种情况就是本地方法需要调用java方法，这时候本地方法栈会保存状态并进入另一个java栈。是虚拟机线程调用Native方法执行时的栈。Java可以通过java本地接口JNI（Java Native Interface）来调用其它语言编写（如C）的程序，在Java里面用native修饰符来描述一个方法是本地方法。虚拟机规范中没有对本地方法栈作强制规定，虚拟机可以自由实现，所以可以不是字节码。如果是以字节码实现的话，虚拟机栈本地方法栈就可以合二为一，事实上，OpenJDK和SunJDK所自带的HotSpot虚拟机就是直接将虚拟机栈和本地方法栈合二为一的。 3个线程私有内存空间的特点？随着线程产生和消亡，因此不需要过多的考虑内存回收的问题，同时在编译时就确定了所需内存的大小 java堆堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，Java堆是被所有线程共享的一块区域，在虚拟机启动的时候创建，此内存区域的唯一目的是存放对象实例，几乎所有的对象实例都在这里分配内存（所有的对象实例和数组都在堆上分配）。 Java堆是垃圾收集器管理的主要区域。也被成为GC堆，Java堆从内存回收的角度可以细分为新生代和老年代，再细分的话，可以分为Eden空间，From Survivor空间，To Survivor空间等，从内存分配的角度来看，java堆中可能划分出多个线程私有的分配缓冲区。不过无论怎么划分，都与存放的内容无关，无论哪个区域，存放的都是对象的实例，进一步划分是为了更好的进行内存回收，或者更快地分配内存。 java虚拟机的规定：Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可。如果在堆中没有完成实例分配，并且堆也无法在扩展时将会抛出OutOfMemoryError异常 方法区方法区域Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态方法、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但它却有一个别名叫做Non-Heap(非堆)，目的应该是与Java堆区分开来。 对于习惯在HotSpot虚拟机上开发、部署程序的开发者来说，很多人都更愿意把方法区成为“永久代”，本质上两者是不等价的，仅仅是因为HotSpot虚拟机的设计团队把GC分代收集扩展至方法区，或者说使用永生代来实现方法区而已，这样HotSpot虚拟机的垃圾回收器可以像管理Java对堆一样管理这部分内存，能够省去专门为这些方法区编写内存管理代码的工作。原则上如何实现方法区属于虚拟机实现细节，不受虚拟机规范的要求，但是用永生代来实现方法区，现在并不是一个好主意，因为这样更容易遇到内存溢出的问题（永生代有-XX：MaxPermSize 的上限，J9和JRockit只要没有触碰到进程可用内存的上限，例如32位系统中的4GB，就不会出现问题），而且有极少数方法会因为这个原因导致不同虚拟机下有不同的表现。因此，对于HotSpot虚拟机，根据官方发布的路线图信息，现在也有放弃永久代并逐步采用Native Memory来实现方法区的规划了，在已经发布的JDK 1.7的HotSpot中，已经把原来放在永久代的字符串常量池移除。 Java虚拟机规范对方法的限制非常宽松，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，一般来说，这个区域的回收“成绩”比较难以令人满意，尤其是类型的卸载，条件相当苛刻，但是这部分区域的回收确实是必要的。在SUN公司的BUG列表中，曾出现过的若干个严重的BUG就是由于低版本的HotSpot虚拟机对此区域未完全回收而导致内存泄漏。 根据Java虚拟机规范的规定，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 运行时常量池什么是OOM？没有空闲内存，并且垃圾收集器也无法提供更多内存。1、堆内存不足是最常见的 OOM 原因之一，抛出的错误信息是“java.lang.OutOfMemoryError:Java heap space”，原因可能千奇百怪，例如，可能存在内存泄漏问题；也很有可能就是堆的大小不合理，比如我们要处理6比较可观的数据量，但是没有显式指定 JVM 堆大小或者指定数值偏小；或者出现 JVM 处理引用不及时，导致堆积起来，内存无法释放等。2、而对于 Java 虚拟机栈和本地方法栈，这里要稍微复杂一点。如果我们写一段程序不断的进行递归调用，而且没有退出条件，就会导致不断地进行压栈。类似这种情况，JVM 实际会抛出 StackOverFlowError；当然，如果JVM 试图去扩展栈空间的的时候失败，则会抛出 OutOfMemoryError。3、 对于老版本的 Oracle JDK，因为永久代的大小是有限的，并且 JVM 对永久代垃圾回收（如，常量池回收、卸载不再需要的类型）非常不积极，所以当我们不断添加新类型的时候，永久代出现 OutOfMemoryError 也非常多见，尤其是在运行时存在大量动态类型生成的场合；类似 Intern 字符串缓存占用太多空间，也会导致 OOM 问题。对应的异常信息，会标记出来和永久代相关：“java.lang.OutOfMemoryError: PermGen space”。4、 随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的 OOM 有所改观，出现 OOM，异常信息则变成了：“java.lang.OutOfMemoryError:Metaspace”。5、直接内存不足，也会导致 OOM。 参考和引用https://blog.csdn.net/qq_33524158/article/details/83348677]]></content>
      <categories>
        <category>java内存管理</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线性回归]]></title>
    <url>%2F2019%2F02%2F27%2F%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在吴恩达的机器学习的视频中有一个房价预测问题，通过真实的一些房价的数据去预测房价。把这些数据画出来，看起来是这个样子：横轴表示房子的面积，单位是平方英尺，纵轴表示房价，单位是千美元。那基于这组数据，现在有一套750平方英尺房子，那么这房子能卖多少钱。 红色的×表示已知的真实的数据集，可以通过一条直线去拟合，大概知道这个房子可以卖150000,但是发现直线的拟合效果并不是很好，可以采用二次方程去拟合（蓝色的线），大概知道这个房子可以卖到200000。 对此，可以根据y=wx+b回归函数从房子的面积对价格进行预测。假设现在有一批房子的面积和对应价格的数据。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990# _*_ encoding=utf8 _*_import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt# 初始化learn_rate = 0.01train_epochs = 1000step = 50# 房子的面积train_x = np.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167, 7.042,10.791,5.313,7.997,5.654,9.27,3.1])# 对应面积的价格train_y = np.asarray([1.7,2.76,2.09,3.19,3.694,1.573,5.366,2.596,3.53,1.221, 4.827,5.465,1.65,3.904,2.42,5.94,1.3])n_samples = train_x.shape[0]# 查看一下数据点的分布plt.scatter(train_x, train_y)plt.show()#定义输入X = tf.placeholder(tf.float32, name = "float")Y = tf.placeholder(tf.float32, name = "float")# 初始化参数 np.random.rand()函数可以返回一个或一组服从“0~1”均匀分布的随机样本值。# 随机样本取值范围是[0,1)W = tf.Variable(np.random.rand(),name = "weight")b = tf.Variable(np.random.rand(),name = "bias")# 线性模型 点乘 对应位置相乘pred = tf.add(tf.multiply(X,W),b)# 损失函数 均方误差函数cost = tf.reduce_sum(tf.pow(pred-Y,2))/(2*n_samples)# 梯度下降算法 去优化cost函数的值 找到最小值 learn_rate下降的步伐optimizer = tf.train.GradientDescentOptimizer(learn_rate).minimize(cost)# 初始化变量init = tf.global_variables_initializer()# 开始训练with tf.Session() as sess: sess.run(init) # 训练样本数据 for epoch in range(train_epochs): for (x,y) in zip(train_x,train_y): # 梯度下降损失函数的最小值 sess.run(optimizer,feed_dict=&#123;X:x,Y:y&#125;) # 训练参数 找到最合适的w b if (epoch+1) % step ==0 : c = sess.run(cost,feed_dict=&#123;X:train_x,Y:train_y&#125;) print("epoch:",'%04d' % (epoch+1),"cost=", "&#123;:.9f&#125;".format(c), "W=", sess.run(W), "b=", sess.run(b)) print("optimizaton finished") training_cost = sess.run(cost, feed_dict=&#123;X:train_x,Y:train_y&#125;) print("最终的cost值=", training_cost, "W=", sess.run(W), "b=", sess.run(b), '\n') #现在训练好了参数w和b 就找到了拟合直线 # 图 x, y r表示红色，o表示实心 label 标识 plt.plot(train_x, train_y, 'ro', label='Original data') plt.plot(train_x, sess.run(W) * train_x + sess.run(b), label='训练集的拟合线') plt.legend() plt.show() # 测试数据 test_x = np.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1]) test_y = np.asarray([3.84, 2.273, 5.2, 4.831, 3.92, 4.24, 1.35, 1.03]) print("均分误差") testing_cost = sess.run( tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * test_x.shape[0]), feed_dict=&#123;X: test_x, Y: test_y&#125;) # 损失函数 print("测试集的损失=", testing_cost) print("均方误差的绝对值:", abs( training_cost - testing_cost)) plt.plot(test_x, test_y, 'bo', label='Testing data') plt.plot(train_y, sess.run(W) * train_x + sess.run(b), label='测试集的拟合线') plt.legend() plt.show() 多元线性回归房价其实不仅仅受到面积的影响，实际上，地理位置、楼层、房子的卧室数量等都会对价格有影响。现在要更久目前下面这些影响点对房价进行预测。人均犯罪率占地面积超过25,000平方英尺的住宅用地比例。每个城镇非零售业务的比例。查尔斯河虚拟变量 如果是大片土地则为1，否则为0氮的氧化物浓度(分之1000万平均每人所住房间数1940年前业主单位所占的比例到达波士顿就业中心的加权距离到达径向公路的系数所有财产价值的每10000美元的税率城镇师生比例城镇黑人比例按照式计算地位较低人士的百分比]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>线性回归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之简单工厂模式]]></title>
    <url>%2F2019%2F02%2F19%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[阅读《大话设计模式》。 简介&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;简单工厂模式：又称为静态工厂方法模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;简单工厂模式设计的角色有三种，分别是工厂，抽象产品和具体产品。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;工厂可以理解为界面，对外沟通，产品理解为业务，内部操作。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;工厂：工程的作用就是创建所有具体产品类的实例。工厂类提供给外部调用，创建对应所需所需的产品对象。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;抽象产品：是所有具体产品角色的父类，它负责描述所有实例所共有的公共接口。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;具体产品：继承自抽象产品角色，一般为多个，是简单工厂模式的创建目标。工厂类返回的都是该角色的某一具体产品。 实例&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实现一个计算器，输入两个数据和运算符号，返回计算结果。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在这里，抽象产品就是一个抽象类，&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;达到的目的，只要输入运算符号，就可以实例化出对应的工厂对象，对于前台界面，只需要关心两个数字和运算符号怎么输入进来，当运算符号进来之后，工厂就会创建出来具体的对象，同时提供出一个运算操作的接口，具体的运算都是去实现这个接口的getResult方法，这样，当运算符号进入工厂类后，根据运算符号，去实例化具体的对象。 运算类： 123public interface Operation &#123; public double getResult(double numberA,double numberB);&#125; 加减乘除四个具体操作的类 123456789/** * 加法 */public class Add implements Operation&#123; @Override public double getResult(double numberA, double numberB) &#123; return numberA + numberB; &#125;&#125; 123456789/** * 减法 */public class Sub implements Operation &#123; @Override public double getResult(double numberA, double numberB) &#123; return numberA - numberB; &#125;&#125; 123456789/** * 乘法 */public class Mul implements Operation &#123; @Override public double getResult(double numberA, double numberB) &#123; return numberA * numberB; &#125;&#125; 123456789/** * 除法 */public class Div implements Operation&#123; @Override public double getResult(double numberA, double numberB) &#123; return numberA/numberB; &#125;&#125; 简单工厂类 1234567891011121314151617181920public class OperatorFactory &#123; public static Operation getOperation(String operator)&#123; Operation operation = null; //多态 switch (operator) &#123; case "+": operation = new Add(); break; case "-": operation = new Sub(); break; case "*": operation = new Mul(); break; case "/": operation = new Div(); break; &#125; return operation; &#125;&#125; 界面类 1234567891011121314javapublic class TestMain &#123; public static void main(String[] args)&#123; Scanner scan = new Scanner(System.in); System.out.println(&quot;请输入第一个数字：&quot;); double numberA = scan.nextDouble(); System.out.println(&quot;请输入第二个数字：&quot;); double numberB = scan.nextDouble(); System.out.println(&quot;请输入操作运算符：&quot;); String operator = scan.next(); Operation oper = OperatorFactory.getOperation(operator); System.out.println(oper.getResult(numberA, numberB)); &#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[knn]]></title>
    <url>%2F2019%2F02%2F18%2Fknn%2F</url>
    <content type="text"><![CDATA[KNN是通过测量不同特征值之间的距离进行分类。它的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别，其中K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 KNN算法的一般流程搜集数据：可以使用任何方法准备数据：距离计算所需要的数值，最好是结构化的数据格式建立一个KNN.py，里面放置数据和标签。 12345678910# _*_ encoding=utf8 _*_from numpy import *import operatordef createDataSet(): group = array([1.1,1.0],[1.0,1.0],[0,0],[0,0.1]) labels = ['A','A','B','B'] return group,labels 分析数据：可以使用任何方法四个点很明显可以看见，分为两类，A标签有两个点，B标签有两个点。 训练算法：此步骤不适用于KNN算法KNN的伪代码思想：对未知类别属性的数据集中的每个点依次执行以下操作：（1）、计算已知类别数据集中的点与当前点之间的操作；（2）、按照距离递增次序排序（3）、选取与当前点距离最小的k个点（4）、确定前k个点所在类别出现的概率（5）、返回前k个点出现概率最高的类别作为当前点的预测分类 KNN的python代码 1234567891011121314151617181920212223def classify(inX,dataSet,labels,k): dataSetSize = dataSet.shape[0] print(dataSetSize) # 获取第一维的维度 4*2 也就是4 # tile 重复inX维度(4,1) inX = [0,0] ==&gt;先横向复制4次，纵向复制1次，也就是本身 最后的维度(4,2) # 这儿求欧式距离，都是求到0 0 的距离 以下几行都是求欧式距离 diffMat = tile(inX, (dataSetSize, 1)) - dataSet sqDiffMat = diffMat ** 2 # 按列求和，也可按行求和axis=1 sqDistances = sqDiffMat.sum(axis=1) print(sqDistances) distances = sqDistances ** 0.5 print(distances) # 返回从小到大的数值的索引 sortedDistIndicies = distances.argsort() print(sortedDistIndicies) classCount = &#123;&#125; for i in range(k): voteIlabel = labels[sortedDistIndicies[i]] # 统计离0 0 最近的范围的标签是什么， classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1 sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True) print(sortedClassCount[0][0]) # 输出预测属于哪一类 测试算法：计算错误率检测分类的结果 123if __name__ == '__main__': group,labels = createDataSet() classify([0,0],group,labels,3) 使用算法：首先需求输入样本数据和结构化的输出结果，然后运行KNN算法判定输入数据分别属于哪一个分类，最后应用对计算出的分类执行后续的处理。约会问题在线约会想找一个适合自己的对象，她把每一个约会对象划分为三类人。 不喜欢的人 魅力一般的人 极具魅力的人 根据哪些特征可以把一个人划分到其中一类呢，她是根据三个特点的分值占比，将一个人划分到某一类，这三个特点是： 每年获得飞行常客里程数 玩视频游戏所占时间百分比 每周消费的冰淇淋公升数数据特征如下： 1234567840920 8.326976 0.953952 314488 7.153469 1.673904 226052 1.441871 0.805124 175136 13.147394 0.428964 138344 1.669788 0.134296 172993 10.141740 1.032955 135948 6.830792 1.213192 342666 13.276369 0.543880 3 首先让文件数据读入内存，训练数据和标记数据分开存储 1234567891011121314def file2matrix(filename): fr = open(filename) numberOfLines = len(fr.readlines()) returnMat = zeros((numberOfLines,3)) classLabelVector = [] fr = codecs.open(filename,'r','utf-8') index = 0 for line in fr.readlines(): line = line.strip() listFromLine = line.split('\t') returnMat[index,:] = listFromLine[0:3] classLabelVector.append(int(listFromLine[-1])) index += 1 return returnMat,classLabelVector 查看一下内存中的训练数据和标签数据代码： 123456if __name__ == '__main__': # group,labels = createDataSet() # classify([0,0],group,labels,3) datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') print(datingDataMat[:3]) print(datingLabels[0:20]) 结果： 1234[[4.092000e+04 8.326976e+00 9.539520e-01] [1.448800e+04 7.153469e+00 1.673904e+00] [2.605200e+04 1.441871e+00 8.051240e-01]][3, 2, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3] 有了数据，有了代码，有了结果标签，就可以从训练数据抽取出一条数据，看看结果预测的对不对选取最后一条数据，数据如下，把他从训练数据文件中删除： 143757 7.882601 1.332446 3 找前3个点出现的概率，测试代码如下： 1234567if __name__ == '__main__': # group,labels = createDataSet() # classify([0,0],group,labels,3) datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') print(datingDataMat[:3]) print(datingLabels[0:20]) classify([43757,7.882601,1.332446], datingDataMat, datingLabels, 3) 。。。预测出来是1，看来是拿到的特征不够，改一行代码试试，找与前100个点的距离 1classify([43757,7.882601,1.332446], datingDataMat, datingLabels, 3) nice，预测出来是3了。 使用Matplotlib创建散点图还是使用刚刚从文件读取出来的数据，查看玩视频游戏消耗时间占比和每周消费冰淇淋的公升数这两个数值，（第一个值太大，不压缩的话其他特征就看不见了，所以不选第一列的值）代码： 123456if __name__ == '__main__': datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') fig = plt.figure() ax = fig.add_subplot(111) ax.scatter(datingDataMat[:,1],datingDataMat[:,2]) plt.show() 结果图横轴是玩视频游戏消耗时间占比，纵轴是每周消费冰淇淋的公升数由于颜色一样，这样的数据显示没什么太大的意义，现在加上标签分类，区分颜色查看这个点属于那一类。下图就是查看第二列和第三列数据，显示的属于哪一类（不喜欢、一般魅力、极具魅力）修改的代码： 12ax.scatter(datingDataMat[:,1],datingDataMat[:,2], 15.0*array(datingLabels),15.0*array(datingLabels)) 结果图： 归一化数值刚刚所说，第一列的数据范围远远大于第二列和第三列的数值范围，所以第一列带来的影响也远远大于其他两列，归一化就是将数据利用一定的比例压缩在0-1之间，这儿使用的方法如下newValue = (oldValue-min)/(max-min)也就是，（当前数据-该列最小数据）/（该列的最大数据-该列的最小数据）代码： 123456789def autoNorm(dataSet): minVals = dataSet.min(0) maxVals = dataSet.max(0) ranges = maxVals - minVals normDataSet = zeros(shape(dataSet)) m = dataSet.shape[0] normDataSet = dataSet - tile(minVals, (m,1)) normDataSet = normDataSet/tile(ranges, (m,1)) return normDataSet, ranges, minVals 好像给了测试数据，测试方法如下： 12345678910111213def datingClassTest(): hoRatio = 0.50 #hold out 10% datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') normMat, ranges, minVals = autoNorm(datingDataMat) m = normMat.shape[0] numTestVecs = int(m*hoRatio) errorCount = 0.0 for i in range(numTestVecs): classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3) print("the classifier came back with: %d, the real answer is: %d" % (classifierResult, datingLabels[i])) if (classifierResult != datingLabels[i]): errorCount += 1.0 print("the total error rate is: %f" % (errorCount/float(numTestVecs))) print(errorCount) 运行测试代码： 12if __name__ == '__main__': datingClassTest() 查看结果： 1234567...the classifier came back with: 2, the real answer is: 2500the classifier came back with: 1, the real answer is: 1500the classifier came back with: 1, the real answer is: 1the total error rate is: 0.064128 可以看见约会问题的分类错误率是6.4128%全部代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394# _*_ encoding=utf8 _*_from numpy import *import operatorimport codecsimport matplotlibimport matplotlib.pyplot as pltdef createDataSet(): group = array([[1.1,1.0],[1.0,1.0],[0.0,0.0],[0.0,0.1]]) labels = ['A','A','B','B'] return group,labelsdef classify(inX,dataSet,labels,k): dataSetSize = dataSet.shape[0] print(dataSetSize) # 获取第一维的维度 4*2 也就是4 # tile 重复inX维度(4,1) inX = [0,0] ==&gt;先横向复制4次，纵向复制1次，也就是本身 最后的维度(4,2) # 这儿求欧式距离，都是求到0 0 的距离 以下几行都是求欧式距离 diffMat = tile(inX, (dataSetSize, 1)) - dataSet sqDiffMat = diffMat ** 2 # 按列求和，也可按行求和axis=1 sqDistances = sqDiffMat.sum(axis=1) # print(sqDistances) distances = sqDistances ** 0.5 # print(distances) # 返回从小到大的数值的索引 sortedDistIndicies = distances.argsort() # print(sortedDistIndicies) classCount = &#123;&#125; for i in range(k): voteIlabel = labels[sortedDistIndicies[i]] # 统计离0 0 最近的范围的标签是什么， classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1 sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True) # print(sortedClassCount[0][0]) # 输出预测属于哪一类 return sortedClassCount[0][0]def file2matrix(filename): fr = open(filename) numberOfLines = len(fr.readlines()) returnMat = zeros((numberOfLines,3)) classLabelVector = [] fr = codecs.open(filename,'r','utf-8') index = 0 for line in fr.readlines(): line = line.strip() listFromLine = line.split('\t') returnMat[index,:] = listFromLine[0:3] classLabelVector.append(int(listFromLine[-1])) index += 1 return returnMat,classLabelVectordef autoNorm(dataSet): minVals = dataSet.min(0) maxVals = dataSet.max(0) ranges = maxVals - minVals normDataSet = zeros(shape(dataSet)) m = dataSet.shape[0] normDataSet = dataSet - tile(minVals, (m,1)) normDataSet = normDataSet/tile(ranges, (m,1)) return normDataSet, ranges, minValsdef datingClassTest(): hoRatio = 0.50 #hold out 10% datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') #load data setfrom file normMat, ranges, minVals = autoNorm(datingDataMat) m = normMat.shape[0] numTestVecs = int(m*hoRatio) errorCount = 0.0 for i in range(numTestVecs): classifierResult = classify(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3) print("the classifier came back with: %d, the real answer is: %d" % (classifierResult, datingLabels[i])) if (classifierResult != datingLabels[i]): errorCount += 1.0 print("the total error rate is: %f" % (errorCount/float(numTestVecs))) print(errorCount)if __name__ == '__main__': # group,labels = createDataSet() # classify([0,0],group,labels,3) # datingDataMat,datingLabels = file2matrix('../data/datingTestSet2.txt') # print(datingDataMat[:3]) # print(datingLabels[0:20]) # classify([43757,7.882601,1.332446], datingDataMat, datingLabels, 100) # fig = plt.figure() # ax = fig.add_subplot(111) # ax.scatter(datingDataMat[:,1],datingDataMat[:,2], # 15.0*array(datingLabels),15.0*array(datingLabels)) # plt.show() datingClassTest() 手写体识别数据分类类似之前的约会问题，构造输入和标签（10分类）就好。构造输入方法也就是读取文件的方法：查看手写体的文件，如下这样一个矩阵刻画出来的阿拉伯数字。 12345678910111213141516171819202122232425262728293031320000000000000111100000000000000000000000000011111110000000000000000000000011111111110000000000000000000111111111111110000000000000000001111111011111100000000000000000111111100000111100000000000000001111111000000011100000000000000011111110000000111100000000000000111111100000000111000000000000001111111000000001110000000000000011111100000000011110000000000000111111000000000011100000000000001111110000000000111000000000000001111110000000000111000000000000011111100000000001110000000000000111111000000000011100000000000001111110000000000111000000000000111111100000000011110000000000001111011000000000111100000000000011110000000000011110000000000000011110000000000011110000000000000111100000000001111100000000000001111000000000111110000000000000011110000000011111000000000000000011100000011111100000000000000000111100011111110000000000000000001111111111111100000000000000000001111111111111000000000000000000011111111111100000000000000000000011111111100000000000000000000000011111000000000000000000000000000011000000000000000000 123456789# 手写体识别是32*32的def img2vector(filename): returnVect = zeros((1,1024)) fr = open(filename) for i in range(32): lineStr = fr.readline() for j in range(32): returnVect[0,32*i+j] = int(lineStr[j]) return returnVect 测试代码: 12345678910111213141516171819202122232425def handwritingClassTest(): hwLabels = [] trainingFileList = os.listdir('../data/trainingDigits') m = len(trainingFileList) trainingMat = zeros((m,1024)) for i in range(m): fileNameStr = trainingFileList[i] fileStr = fileNameStr.split('.')[0] classNumStr = int(fileStr.split('_')[0]) hwLabels.append(classNumStr) trainingMat[i,:] = img2vector('../data/trainingDigits/%s' % fileNameStr) testFileList = os.listdir('../data/testDigits') errorCount = 0.0 mTest = len(testFileList) for i in range(mTest): fileNameStr = testFileList[i] fileStr = fileNameStr.split('.')[0] classNumStr = int(fileStr.split('_')[0]) vectorUnderTest = img2vector('../data/testDigits/%s' % fileNameStr) classifierResult = classify(vectorUnderTest, trainingMat, hwLabels, 3) print("the classifier came back with: %d, the real answer is: %d" % (classifierResult, classNumStr)) if (classifierResult != classNumStr): errorCount += 1.0 print("\nthe total number of errors is: %d" % errorCount) print("\nthe total error rate is: %f" % (errorCount/float(mTest))) 结果： 123the total number of errors is: 11the total error rate is: 0.011628 Tensorflow版本KNN代码1234567891011121314151617181920212223242526272829303132333435363738394041424344# _*_ encoding=utf8 _*_import numpy as npimport tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_data# 导入手写体识别的数据mnist = input_data.read_data_sets("../data", one_hot=True)# 训练集和测试集X_train, Y_train = mnist.train.next_batch(5000) # 数据和labelsX_test, Y_test = mnist.test.next_batch(100)# 定义输入x_train = tf.placeholder(tf.float32, shape=(None,784))x_test = tf.placeholder(tf.float32, shape=(784))# L1距离也就是城市街区距离 |x1-x2|+|y1-y2|distance = tf.reduce_sum(tf.abs(tf.add(x_train,tf.negative(x_test))),reduction_indices = 1)# 返回最近的坐标，0纵轴 1横轴pred = tf.arg_min(distance, 0)accuracy = 0# 初始化init = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) for i in range(len(X_test)): # 获取当前样本的最近邻索引，当前样本和每一个训练的样本找一个最近的l1距离，得到这个最小距离的下标 nn_index = sess.run(pred, feed_dict=&#123;x_train:X_train, x_test: X_test[i, :]&#125;) # 由最邻近索引找到label,然后最邻近的label与真实标签比较 np.argmax找最大的下标 # 由l1距离找到的最小值对应的坐标，通过该最坐标找到对应行label的最大值的下标，这个下标对应的就是数字的大小 print("预测次数", i, "预测标签:", np.argmax(Y_train[nn_index]),"真实标签:", np.argmax(Y_test[i])) # 计算准确率 if np.argmax(Y_train[nn_index]) == np.argmax(Y_test[i]): accuracy += 1print("Accuracy:", float(accuracy)/len(X_test))]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>knn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[书单]]></title>
    <url>%2F2019%2F02%2F18%2F%E4%B9%A6%E5%8D%95%2F</url>
    <content type="text"><![CDATA[《架构整洁之道》]]></content>
      <categories>
        <category>书单</category>
      </categories>
      <tags>
        <tag>书单</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018目标]]></title>
    <url>%2F2018%2F11%2F22%2F2018%E7%9B%AE%E6%A0%87%2F</url>
    <content type="text"><![CDATA[思前想后，在2018结尾之际，好吧就是结尾，但是也需要在春节之前给自己一个目标，安慰一下这一年犹豫不决的心吧。 我觉得应该从书单和知识点都出发吧。整理一下思路，好像目前博客不能评论... ## 书单 &lt;!--more--&gt; ## 知识点 word2vec 的CBOW和Skip-Gram fasttext textcnn sent2vec capsnet attention seq2seq idcnn Encoder-Decoder]]></content>
      <categories>
        <category>计划</category>
      </categories>
      <tags>
        <tag>计划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一篇文章]]></title>
    <url>%2F2018%2F11%2F04%2F%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[有种爱，只离你一转身的距离 他是你前世遗落的一滴泪，今生，不管谁人装饰你的梦，他的梦只有你是唯一的点缀;不管你呼唤的人是谁，你的名字是他心里梦里唯一的执念不悔。 ——题记 人世间，或许你本是烙在他心头的一颗朱砂，最后却成了一朵让他可望而不可及的彼岸花。不知是光阴的交错，还是轮回的因果，有种爱，永远只离你一转身的距离，一旦开始，永无结束。你来，瘦了他的幽梦;你去，肥了他的相思。 爱是种很玄的东西，说不清，道不明，剪不断，理还乱。世上，有种爱明知没有结果，却依然坚守原地，不舍离去，哪怕握不住你的一丝余温，他依然选取默默为你守候。一路来去，他的心门只为你独开，他的山城只为你独驻，他的白天只为你旖旎，他的黑夜只为你流连。哪怕他因为爱你，心入住荒岛，他还是会以最深情的眼神，看着你幸福。 自爱上你的那天起，思念便成了他戒不掉的瘾。你的一言一笑，一颦一蹙，无不牵动他的心，百千尘思，他唯念一缕;万千红颜，他唯恋一人。他愿意一生漂泊浪迹在你的故事里，甘愿为你鞍前马后，马首是瞻，即使你从未给他一句承诺，即使你从未给他半分感情，他依然无悔无怨。 正如张爱玲说的“等待雨，是伞一世的宿命”。当你深植在他心里，那么任何力量都无法将你从他心中除去。不管你是不是他身边的卷帘人，不管你是不是他罗帐里的共眠者，他的目光将一向被你牵引，他的感情故事里，你必须是无可替代的主角，从此，他的等待里，愿望里，祝福里，牵挂里，都会有你。他能够戒掉一切，但就是戒不掉你。 只因当初在人群中多看了你一眼，从此，他再未走远。他不轻易靠近打扰，是怕自己扰了你的生活步调;他不轻易对你开口言爱，是怕那样做是一种冒犯，是一种亵渎，是一种伤害;他不轻易换手机号码，是怕你担心找他不见。因为爱，他能够为你低到尘埃，能够为你放弃日月山河，能够为你浪迹海角天涯。他不在乎他的四季有没有春天，因为只有你才是他的人间四月天;他不在乎他生活在白天还是黑夜，因为只有你才能照亮他的全世界。 其实他害怕寂寞，但他因为你会让自己陷进很深的寂寞;其实他害怕孤独，但他因为你会让自己紧紧追随着孤独。他多么期望，你能懂他沉默，懂他无声，懂他的欲言又止。有时你看不见他，是因为他悄悄藏在了你身后;有时你听不见他，是因为他偷偷用静默伪装了自己。纵然他离你山高水远，只要你对他呼唤，他必须能快速抵达;纵然他有万事牵绊，只要你对他招手，他必须会义无反顾。 你让他难过了，他会笑着说无所谓;你让他受伤了，他会找理由来原谅。你若欢笑，也许他会比你笑得更灿烂;你若流泪，也许他会比你更难过。因为你，他会爱上你住的那座城，你住的地方，是他梦里梦外辗转的心驰神往。距离，隔不断他的爱恋;时间，冲不淡他的思念。任季节轮回，他始终认为，今生只为你而来，哪怕今生终是错过，他还会傻傻地预约来生。 走在南国，他会渴望共你摇橹，游遍江南的烟雨水乡;走在北国，他会期盼与你共沐飞雪，穿越雪帘走向梦中的童话。他的脚步随你飘移，他的心跳随你跳动。莫名的，看到一个与你相似的身影，听见一个与你相似的声音，他都会激动良久。无论何时，无论何地，他都在用另一种不为你所知的方式，悄悄地爱你。 徐志摩说：“一生至少该有一次，为了某个人而忘了自己，不求有结果，不求同行，不求以前拥有，甚至不求你爱我，只求在我最美的年华里，遇到你。”他就是如此，今生遇见你，他觉得是他的幸福，尽管这幸福里交杂着万千痛苦。 人生有期，但这份守候永不落幕，繁华红尘，谁染指了谁的幸福于他而言，江山如画，怎敌你眉间的一点朱砂你，永远是他描不完的画、读不厌的景。无论何时，你若回首，你会发现，他永远只离你一转身的距离，人在那里，从未稍离!]]></content>
      <categories>
        <category>hexo使用教程</category>
      </categories>
      <tags>
        <tag>散文</tag>
        <tag>测试</tag>
      </tags>
  </entry>
</search>
